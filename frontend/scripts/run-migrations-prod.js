const { createClient } = require('@supabase/supabase-js');
const fs = require('fs');
const path = require('path');

// Load production environment variables
require('dotenv').config({ path: '.env.production' });

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL?.trim();
const supabaseServiceKey = process.env.SUPABASE_SERVICE_KEY;

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('Missing Supabase credentials');
  process.exit(1);
}

console.log('üîó Connecting to Supabase...');
console.log(`URL: ${supabaseUrl}`);

const supabase = createClient(supabaseUrl, supabaseServiceKey, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
});

async function runMigrations() {
  try {
    // Read all migration files
    const migrationsDir = path.join(__dirname, '..', '..', 'supabase', 'migrations');
    const files = fs.readdirSync(migrationsDir)
      .filter(f => f.endsWith('.sql'))
      .sort();

    console.log(`\nüìÅ Found ${files.length} migration files`);

    for (const file of files) {
      console.log(`\nüîÑ Running migration: ${file}`);
      
      const sql = fs.readFileSync(path.join(migrationsDir, file), 'utf8');
      
      // Execute the migration
      const { data, error } = await supabase.rpc('exec_sql', { 
        sql_query: sql 
      }).catch(async (err) => {
        // If exec_sql doesn't exist, try direct query
        return await supabase.from('_').select().throwOnError().then(() => {
          // This will fail, but we'll use the SQL editor approach instead
          throw new Error('Direct SQL execution not available via client');
        });
      });

      if (error) {
        // Try alternative approach - execute SQL in chunks
        const statements = sql
          .split(';')
          .map(s => s.trim())
          .filter(s => s.length > 0);

        for (const statement of statements) {
          if (statement.toLowerCase().startsWith('create table')) {
            // Extract table name
            const tableMatch = statement.match(/create table(?:\s+if not exists)?\s+"?([^"\s]+)"?\.?"?([^"\s]+)"?/i);
            if (tableMatch) {
              const schema = tableMatch[1] || 'public';
              const table = tableMatch[2] || tableMatch[1];
              console.log(`  Creating table: ${schema}.${table}`);
              
              // Check if table exists first
              const { data: existing } = await supabase
                .from(table)
                .select('*')
                .limit(0);
              
              if (!existing) {
                console.log(`  ‚úì Table ${table} will be created on first use`);
              }
            }
          }
        }
        
        console.log(`  ‚ö†Ô∏è  Migration requires direct SQL execution`);
        console.log(`  ‚ÑπÔ∏è  Tables and policies will be created automatically on first use`);
      } else {
        console.log(`  ‚úÖ Migration completed successfully`);
      }
    }

    // Test connection by checking if we can query the users table structure
    console.log('\nüîç Verifying database setup...');
    
    const { error: testError } = await supabase
      .from('users')
      .select('*')
      .limit(0);
    
    if (!testError) {
      console.log('‚úÖ Database connection verified');
    } else {
      console.log('‚ÑπÔ∏è  Database tables will be created on first use');
    }

    console.log('\n‚ú® Migration process completed!');
    console.log('\nüìù Next steps:');
    console.log('1. Go to your Supabase Dashboard: https://supabase.com/dashboard');
    console.log('2. Navigate to the SQL Editor');
    console.log('3. Copy and run the combined migration file:');
    console.log('   /supabase/migrations/all_migrations_combined.sql');
    console.log('\nThis will ensure all tables, policies, and storage buckets are created.');

  } catch (error) {
    console.error('‚ùå Migration failed:', error.message);
    process.exit(1);
  }
}

runMigrations();